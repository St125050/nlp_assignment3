{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "3aX92yHd2EcS",
        "outputId": "6a7ec341-ef33-424f-ca87-cbf1e6923a20"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28d18988-e2d6-4354-98c8-69a5967215e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28d18988-e2d6-4354-98c8-69a5967215e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sentence-aligned.v2.tar.gz to sentence-aligned.v2.tar.gz\n",
            "Extracted Files: ['sentence-aligned.v2']\n",
            "✅ Cleaned dataset saved at: /content/cleaned_sentence_aligned.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c183256-21ad-42f8-8919-36aaebbb6383\", \"cleaned_sentence_aligned.csv\", 44354069)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 1: Upload the dataset (Manual Step)\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload \"sentence-aligned.v2.tar.gz\" from your local machine\n",
        "\n",
        "# Step 2: Extract the dataset\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "file_path = \"sentence-aligned.v2.tar.gz\"  # Use the uploaded file\n",
        "extract_path = \"/content/sentence_aligned_v2\"\n",
        "\n",
        "# Extract the tar.gz file\n",
        "with tarfile.open(file_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "# Step 3: Check extracted files\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted Files:\", extracted_files)\n",
        "\n",
        "# Step 4: Read the data files\n",
        "normal_file = os.path.join(extract_path, \"sentence-aligned.v2\", \"normal.aligned\")\n",
        "simple_file = os.path.join(extract_path, \"sentence-aligned.v2\", \"simple.aligned\")\n",
        "\n",
        "# Step 5: Clean the dataset (Extract actual sentences)\n",
        "def clean_sentences(file_path):\n",
        "    cleaned_sentences = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            if len(parts) > 2:  # Ensure it has the expected format\n",
        "                cleaned_sentences.append(parts[-1])  # Take the actual sentence\n",
        "    return cleaned_sentences\n",
        "\n",
        "# Clean both files\n",
        "cleaned_normal_sentences = clean_sentences(normal_file)\n",
        "cleaned_simple_sentences = clean_sentences(simple_file)\n",
        "\n",
        "# Step 6: Create a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "df_cleaned = pd.DataFrame({\"Standard English\": cleaned_normal_sentences, \"Simple English\": cleaned_simple_sentences})\n",
        "\n",
        "# Step 7: Save the cleaned dataset to Colab's /content directory\n",
        "cleaned_file_path = \"/content/cleaned_sentence_aligned.csv\"\n",
        "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
        "print(f\"✅ Cleaned dataset saved at: {cleaned_file_path}\")\n",
        "\n",
        "# Step 8: Allow Download (Optional - If you want to save to local machine)\n",
        "files.download(cleaned_file_path)  # This will download the file to your computer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned dataset from /content/\n",
        "cleaned_file_path = \"/content/cleaned_sentence_aligned.csv\"\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(cleaned_file_path)\n",
        "\n",
        "# Display the first 10 rows\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "fjCyaBm0DzB_",
        "outputId": "7e540820-c971-44fb-e266-ba4eac561b78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Standard English  \\\n",
              "0          It is the county seat of Alfalfa County .   \n",
              "1  Cherokee is a city in Alfalfa County , Oklahom...   \n",
              "2  Skateboard decks are usually between 28 and 33...   \n",
              "3  The underside of the deck can be printed with ...   \n",
              "4  This was created by two surfers ; Ben Whatson ...   \n",
              "5  Some of them have special materials that help ...   \n",
              "6  `` Old school '' boards -LRB- those made in th...   \n",
              "7  One of the first deck companies was called `` ...   \n",
              "8  Grip tape , when applied to the top surface of...   \n",
              "9  Modern decks vary in size , but most are 7 to ...   \n",
              "\n",
              "                                      Simple English  \n",
              "0          It is the county seat of Alfalfa County .  \n",
              "1  Cherokee is a city of Oklahoma in the United S...  \n",
              "2  Skateboard decks are normally between 28 and 3...  \n",
              "3  The bottom of the deck can be printed with a d...  \n",
              "4  The longboard was made by two surfers ; Ben Wh...  \n",
              "5  Other materials used in making decks fiberglas...  \n",
              "6  `` Old school '' boards -LRB- those made in th...  \n",
              "7  One of the first deck companies was called `` ...  \n",
              "8  Grip tape , when put on to the top of a skateb...  \n",
              "9  Modern decks are different in size . Most are ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-248fb700-580c-45c9-9470-e595c2debbe6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Standard English</th>\n",
              "      <th>Simple English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It is the county seat of Alfalfa County .</td>\n",
              "      <td>It is the county seat of Alfalfa County .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cherokee is a city in Alfalfa County , Oklahom...</td>\n",
              "      <td>Cherokee is a city of Oklahoma in the United S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Skateboard decks are usually between 28 and 33...</td>\n",
              "      <td>Skateboard decks are normally between 28 and 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The underside of the deck can be printed with ...</td>\n",
              "      <td>The bottom of the deck can be printed with a d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This was created by two surfers ; Ben Whatson ...</td>\n",
              "      <td>The longboard was made by two surfers ; Ben Wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Some of them have special materials that help ...</td>\n",
              "      <td>Other materials used in making decks fiberglas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>`` Old school '' boards -LRB- those made in th...</td>\n",
              "      <td>`` Old school '' boards -LRB- those made in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>One of the first deck companies was called `` ...</td>\n",
              "      <td>One of the first deck companies was called `` ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Grip tape , when applied to the top surface of...</td>\n",
              "      <td>Grip tape , when put on to the top of a skateb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Modern decks vary in size , but most are 7 to ...</td>\n",
              "      <td>Modern decks are different in size . Most are ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-248fb700-580c-45c9-9470-e595c2debbe6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-248fb700-580c-45c9-9470-e595c2debbe6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-248fb700-580c-45c9-9470-e595c2debbe6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a650d350-08bf-470d-9868-462a54a99715\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a650d350-08bf-470d-9868-462a54a99715')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a650d350-08bf-470d-9868-462a54a99715 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b9h0nB4D5hQ",
        "outputId": "eb890f78-0ae9-455d-df94-5d3679228cb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1+cu124\n",
            "Uninstalling torch-2.5.1+cu124:\n",
            "  Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchtext==0.15.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGVbuxXtGU0g",
        "outputId": "7528ebd7-ef5d-4222-a04d-6903e40fd55b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"TorchText version: {torchtext.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxj1cQccGZR4",
        "outputId": "6305da80-55fc-40a8-9022-cb2678f991c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.1+cu117\n",
            "TorchText version: 0.15.2+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itk4qkKtGb0G",
        "outputId": "d3cbcc5d-f704-4e8a-c4b4-ae91b6990042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "oVgKMaAbGfHy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AxjMabJHBHS",
        "outputId": "3eeeff0e-a7ff-4064-eaa3-353b7d61cfa8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/cleaned_sentence_aligned.csv\")\n",
        "\n",
        "# Define source and target languages\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'comic'"
      ],
      "metadata": {
        "id": "LwVjKBupHGAU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "token_transform = {}\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
        "token_transform[TRG_LANGUAGE] = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# Tokenize dataset\n",
        "df[\"Standard English Tokens\"] = df[\"Standard English\"].apply(token_transform[SRC_LANGUAGE])\n",
        "df[\"Comic English Tokens\"] = df[\"Simple English\"].apply(token_transform[TRG_LANGUAGE])\n"
      ],
      "metadata": {
        "id": "4kp31VamHZST"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 10 rows with tokens\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHUP5jSpHqR0",
        "outputId": "8ed799c3-ce02-4503-d780-0a2c3ab9109b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    Standard English  \\\n",
            "0          It is the county seat of Alfalfa County .   \n",
            "1  Cherokee is a city in Alfalfa County , Oklahom...   \n",
            "2  Skateboard decks are usually between 28 and 33...   \n",
            "3  The underside of the deck can be printed with ...   \n",
            "4  This was created by two surfers ; Ben Whatson ...   \n",
            "5  Some of them have special materials that help ...   \n",
            "6  `` Old school '' boards -LRB- those made in th...   \n",
            "7  One of the first deck companies was called `` ...   \n",
            "8  Grip tape , when applied to the top surface of...   \n",
            "9  Modern decks vary in size , but most are 7 to ...   \n",
            "\n",
            "                                      Simple English  \\\n",
            "0          It is the county seat of Alfalfa County .   \n",
            "1  Cherokee is a city of Oklahoma in the United S...   \n",
            "2  Skateboard decks are normally between 28 and 3...   \n",
            "3  The bottom of the deck can be printed with a d...   \n",
            "4  The longboard was made by two surfers ; Ben Wh...   \n",
            "5  Other materials used in making decks fiberglas...   \n",
            "6  `` Old school '' boards -LRB- those made in th...   \n",
            "7  One of the first deck companies was called `` ...   \n",
            "8  Grip tape , when put on to the top of a skateb...   \n",
            "9  Modern decks are different in size . Most are ...   \n",
            "\n",
            "                             Standard English Tokens  \\\n",
            "0  [It, is, the, county, seat, of, Alfalfa, Count...   \n",
            "1  [Cherokee, is, a, city, in, Alfalfa, County, ,...   \n",
            "2  [Skateboard, decks, are, usually, between, 28,...   \n",
            "3  [The, underside, of, the, deck, can, be, print...   \n",
            "4  [This, was, created, by, two, surfers, ;, Ben,...   \n",
            "5  [Some, of, them, have, special, materials, tha...   \n",
            "6  [`, `, Old, school, '', boards, -LRB-, those, ...   \n",
            "7  [One, of, the, first, deck, companies, was, ca...   \n",
            "8  [Grip, tape, ,, when, applied, to, the, top, s...   \n",
            "9  [Modern, decks, vary, in, size, ,, but, most, ...   \n",
            "\n",
            "                                Comic English Tokens  \n",
            "0  [it, is, the, county, seat, of, alfalfa, count...  \n",
            "1  [cherokee, is, a, city, of, oklahoma, in, the,...  \n",
            "2  [skateboard, decks, are, normally, between, 28...  \n",
            "3  [the, bottom, of, the, deck, can, be, printed,...  \n",
            "4  [the, longboard, was, made, by, two, surfers, ...  \n",
            "5  [other, materials, used, in, making, decks, fi...  \n",
            "6  [``, old, school, ', ', boards, -lrb-, those, ...  \n",
            "7  [one, of, the, first, deck, companies, was, ca...  \n",
            "8  [grip, tape, ,, when, put, on, to, the, top, o...  \n",
            "9  [modern, decks, are, different, in, size, ., m...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Vocabulary\n",
        "def yield_tokens(data_column):\n",
        "    for sentence in data_column:\n",
        "        yield sentence\n",
        "\n",
        "vocab_transform = {}\n",
        "vocab_transform[SRC_LANGUAGE] = build_vocab_from_iterator(yield_tokens(df[\"Standard English Tokens\"]), min_freq=2, specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
        "vocab_transform[TRG_LANGUAGE] = build_vocab_from_iterator(yield_tokens(df[\"Comic English Tokens\"]), min_freq=2, specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(vocab_transform[ln][\"<unk>\"])\n"
      ],
      "metadata": {
        "id": "L3mwi2tZH7Az"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "PAD_IDX = vocab_transform[SRC_LANGUAGE][\"<pad>\"]\n",
        "SOS_IDX = vocab_transform[SRC_LANGUAGE][\"<sos>\"]\n",
        "EOS_IDX = vocab_transform[SRC_LANGUAGE][\"<eos>\"]\n",
        "\n",
        "# Convert text into tensor\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])))\n",
        "\n",
        "# Sequential Transforms\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = lambda x: tensor_transform(vocab_transform[ln](token_transform[ln](x)))\n"
      ],
      "metadata": {
        "id": "xfLbSwsSH_ow"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collation\n",
        "def collate_batch(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "# Create Dataloaders\n",
        "batch_size = 16\n",
        "dataset = list(zip(df[\"Standard English\"], df[\"Simple English\"]))\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_data, val_data, test_data = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "7s6oCfvcIGjq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Attention Mechanism\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        if method == \"general\":\n",
        "            self.attn = nn.Linear(hidden_size, hidden_size)\n",
        "        elif method == \"multiplicative\":\n",
        "            self.attn = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        elif method == \"additive\":\n",
        "            self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        batch_size, seq_len, _ = encoder_outputs.shape\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "\n",
        "        if self.method == \"general\":\n",
        "            energy = self.attn(encoder_outputs)\n",
        "            attention_weights = torch.bmm(hidden, energy.permute(0, 2, 1)).squeeze(1)\n",
        "        elif self.method == \"multiplicative\":\n",
        "            energy = torch.matmul(hidden, self.attn(encoder_outputs).permute(0, 2, 1))\n",
        "            attention_weights = energy.squeeze(1)\n",
        "        elif self.method == \"additive\":\n",
        "            energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "            attention_weights = torch.sum(self.v * energy, dim=2)\n",
        "        return torch.softmax(attention_weights, dim=1)"
      ],
      "metadata": {
        "id": "Cn_abEwbIMmA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Transformer-based Seq2Seq Model with Attention\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hid_dim=128, n_layers=2, n_heads=4, pf_dim=256, dropout=0.1, attn_type=\"general\"):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Embedding(input_dim, hid_dim)\n",
        "        self.decoder = nn.Embedding(output_dim, hid_dim)\n",
        "        self.transformer = nn.Transformer(d_model=hid_dim, nhead=n_heads, num_encoder_layers=n_layers, num_decoder_layers=n_layers, dim_feedforward=pf_dim, dropout=dropout, batch_first=True)\n",
        "        self.attention = Attention(attn_type, hid_dim)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        enc_src = self.encoder(src)\n",
        "        dec_trg = self.decoder(trg)\n",
        "        transformer_output = self.transformer(enc_src, dec_trg)\n",
        "        attn_weights = self.attention(enc_src[:, -1, :], enc_src)\n",
        "        return self.fc_out(transformer_output), attn_weights\n",
        "\n"
      ],
      "metadata": {
        "id": "4w2oLkcRIRhs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear memory before training\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-85HVATZsP5",
        "outputId": "ca55d1fa-ef24-4e03-a65a-6b45b5f4f34e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model\n",
        "input_dim = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim = len(vocab_transform[TRG_LANGUAGE])\n",
        "hid_dim = 128\n",
        "n_layers = 2\n",
        "n_heads = 4\n",
        "pf_dim = 256\n",
        "dropout = 0.1\n",
        "attn_type = \"additive\"\n",
        "\n",
        "model = Seq2SeqTransformer(input_dim, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, attn_type).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "metadata": {
        "id": "DJcnEdnnIqgm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate Model with Different Attention Mechanisms\n",
        "attention_types = [\"general\", \"multiplicative\", \"additive\"]\n",
        "results = {}"
      ],
      "metadata": {
        "id": "5sCtYED0rgGE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize results dictionary\n",
        "results = {attn_type: {\"train_loss\": [], \"val_loss\": [], \"train_ppl\": [], \"val_ppl\": []} for attn_type in [\"general\", \"multiplicative\", \"additive\"]}\n"
      ],
      "metadata": {
        "id": "TtWrKjOL19jE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence_tokens, translation_tokens, attention_weights, attn_type):\n",
        "    \"\"\"\n",
        "    Display and save attention weights between input (source) and output (target) tokens.\n",
        "    \"\"\"\n",
        "    # Convert tensor to numpy\n",
        "    attention = attention_weights.squeeze(0).cpu().detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    cax = ax.matshow(attention, cmap='Blues', aspect='auto')\n",
        "\n",
        "    # Set axis labels\n",
        "    ax.set_xticklabels([''] + sentence_tokens, rotation=45, ha='left', fontsize=10)\n",
        "    ax.set_yticklabels([''] + translation_tokens, fontsize=10)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    # Color bar\n",
        "    fig.colorbar(cax)\n",
        "    plt.title(f\"Attention Map - {attn_type} Attention\", fontsize=12)\n",
        "\n",
        "    # Save attention map\n",
        "    save_path = f\"attention_map_{attn_type}.png\"\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    print(f\"✅ Saved attention map as {save_path}\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "BO1vT1572XT_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate Model with Time Tracking and Generate Attention Maps\n",
        "for attn_type in results.keys():\n",
        "    print(f\"Training with {attn_type} attention...\")\n",
        "\n",
        "    model = Seq2SeqTransformer(len(vocab_transform[SRC_LANGUAGE]), len(vocab_transform[TRG_LANGUAGE]), attn_type=attn_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for src, trg in train_loader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, attn_weights = model(src, trg[:, :-1])\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        train_loss = epoch_loss / len(train_loader)\n",
        "        train_ppl = math.exp(train_loss)\n",
        "        results[attn_type][\"train_loss\"].append(train_loss)\n",
        "        results[attn_type][\"train_ppl\"].append(train_ppl)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for src, trg in valid_loader:\n",
        "                src, trg = src.to(device), trg.to(device)\n",
        "                output, attn_weights = model(src, trg[:, :-1])\n",
        "                loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss = val_loss / len(valid_loader)\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        results[attn_type][\"val_loss\"].append(val_loss)\n",
        "        results[attn_type][\"val_ppl\"].append(val_ppl)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Loss = {train_loss:.3f}, Train PPL = {train_ppl:.3f}, Val Loss = {val_loss:.3f}, Val PPL = {val_ppl:.3f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    results[attn_type][\"training_time\"] = end_time - start_time\n",
        "    print(f\"Training Time for {attn_type}: {results[attn_type]['training_time']:.2f} seconds\")\n",
        "\n",
        "    # Generate and Save Attention Maps AFTER training for this attention type\n",
        "    print(f\"Generating Attention Map for {attn_type} Attention...\")\n",
        "\n",
        "    # Select a random batch from training data\n",
        "    src_text, trg_text = next(iter(train_loader))\n",
        "    src_text, trg_text = src_text.to(device), trg_text.to(device)\n",
        "\n",
        "    # Run the trained model to get attention weights\n",
        "    with torch.no_grad():\n",
        "        output, attn_weights = model(src_text, trg_text[:, :-1])\n",
        "\n",
        "    # Decode tokens into words for visualization\n",
        "    source_tokens = [vocab_transform[SRC_LANGUAGE].lookup_token(idx) for idx in src_text[0].tolist()]\n",
        "    target_tokens = [vocab_transform[TRG_LANGUAGE].lookup_token(idx) for idx in trg_text[0].tolist()]\n",
        "\n",
        "    # Display and save attention map\n",
        "    display_attention(source_tokens, target_tokens, attn_weights[0], attn_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te-rVr5W1x2n",
        "outputId": "d56bf057-430b-4005-f253-5f277ff2e413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with general attention...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate Model with Time Tracking\n",
        "for attn_type in results.keys():\n",
        "    print(f\"Training with {attn_type} attention...\")\n",
        "    model = Seq2SeqTransformer(len(vocab_transform[SRC_LANGUAGE]), len(vocab_transform[TRG_LANGUAGE]), attn_type=attn_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for src, trg in train_loader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, _ = model(src, trg[:, :-1])\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        train_loss = epoch_loss / len(train_loader)\n",
        "        train_ppl = math.exp(train_loss)\n",
        "        results[attn_type][\"train_loss\"].append(train_loss)\n",
        "        results[attn_type][\"train_ppl\"].append(train_ppl)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for src, trg in valid_loader:\n",
        "                src, trg = src.to(device), trg.to(device)\n",
        "                output, _ = model(src, trg[:, :-1])\n",
        "                loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "                val_loss += loss.item()\n",
        "        val_loss = val_loss / len(valid_loader)\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        results[attn_type][\"val_loss\"].append(val_loss)\n",
        "        results[attn_type][\"val_ppl\"].append(val_ppl)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Loss = {train_loss:.3f}, Train PPL = {train_ppl:.3f}, Val Loss = {val_loss:.3f}, Val PPL = {val_ppl:.3f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    results[attn_type][\"training_time\"] = end_time - start_time\n",
        "    print(f\"Training Time for {attn_type}: {results[attn_type]['training_time']:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8pGYH6m2Fgn",
        "outputId": "51def481-cd91-4738-951c-e763e604d66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with general attention...\n",
            "Epoch 1: Train Loss = 5.196, Train PPL = 180.542, Val Loss = 4.464, Val PPL = 86.815\n",
            "Epoch 2: Train Loss = 4.154, Train PPL = 63.692, Val Loss = 3.970, Val PPL = 52.963\n",
            "Epoch 3: Train Loss = 3.656, Train PPL = 38.698, Val Loss = 3.708, Val PPL = 40.777\n",
            "Epoch 4: Train Loss = 3.329, Train PPL = 27.912, Val Loss = 3.549, Val PPL = 34.778\n",
            "Epoch 5: Train Loss = 3.096, Train PPL = 22.100, Val Loss = 3.452, Val PPL = 31.563\n",
            "Epoch 6: Train Loss = 2.925, Train PPL = 18.626, Val Loss = 3.383, Val PPL = 29.464\n",
            "Epoch 7: Train Loss = 2.794, Train PPL = 16.352, Val Loss = 3.341, Val PPL = 28.246\n",
            "Epoch 8: Train Loss = 2.693, Train PPL = 14.781, Val Loss = 3.308, Val PPL = 27.323\n",
            "Epoch 9: Train Loss = 2.610, Train PPL = 13.598, Val Loss = 3.277, Val PPL = 26.498\n",
            "Epoch 10: Train Loss = 2.541, Train PPL = 12.696, Val Loss = 3.259, Val PPL = 26.015\n",
            "Training Time for general: 3050.46 seconds\n",
            "Training with multiplicative attention...\n",
            "Epoch 1: Train Loss = 5.193, Train PPL = 179.972, Val Loss = 4.471, Val PPL = 87.436\n",
            "Epoch 2: Train Loss = 4.158, Train PPL = 63.913, Val Loss = 3.980, Val PPL = 53.500\n",
            "Epoch 3: Train Loss = 3.658, Train PPL = 38.800, Val Loss = 3.709, Val PPL = 40.829\n",
            "Epoch 4: Train Loss = 3.330, Train PPL = 27.943, Val Loss = 3.560, Val PPL = 35.174\n",
            "Epoch 5: Train Loss = 3.098, Train PPL = 22.145, Val Loss = 3.460, Val PPL = 31.830\n",
            "Epoch 6: Train Loss = 2.926, Train PPL = 18.656, Val Loss = 3.396, Val PPL = 29.847\n",
            "Epoch 7: Train Loss = 2.795, Train PPL = 16.358, Val Loss = 3.350, Val PPL = 28.506\n",
            "Epoch 8: Train Loss = 2.693, Train PPL = 14.769, Val Loss = 3.314, Val PPL = 27.486\n",
            "Epoch 9: Train Loss = 2.610, Train PPL = 13.601, Val Loss = 3.281, Val PPL = 26.610\n",
            "Epoch 10: Train Loss = 2.543, Train PPL = 12.719, Val Loss = 3.260, Val PPL = 26.052\n",
            "Training Time for multiplicative: 3069.24 seconds\n",
            "Training with additive attention...\n",
            "Epoch 1: Train Loss = 5.209, Train PPL = 182.961, Val Loss = 4.480, Val PPL = 88.240\n",
            "Epoch 2: Train Loss = 4.167, Train PPL = 64.534, Val Loss = 3.975, Val PPL = 53.251\n",
            "Epoch 3: Train Loss = 3.662, Train PPL = 38.938, Val Loss = 3.706, Val PPL = 40.678\n",
            "Epoch 4: Train Loss = 3.328, Train PPL = 27.896, Val Loss = 3.558, Val PPL = 35.097\n",
            "Epoch 5: Train Loss = 3.096, Train PPL = 22.114, Val Loss = 3.458, Val PPL = 31.748\n",
            "Epoch 6: Train Loss = 2.925, Train PPL = 18.628, Val Loss = 3.393, Val PPL = 29.745\n",
            "Epoch 7: Train Loss = 2.793, Train PPL = 16.325, Val Loss = 3.341, Val PPL = 28.238\n",
            "Epoch 8: Train Loss = 2.691, Train PPL = 14.748, Val Loss = 3.300, Val PPL = 27.117\n",
            "Epoch 9: Train Loss = 2.610, Train PPL = 13.598, Val Loss = 3.279, Val PPL = 26.562\n",
            "Epoch 10: Train Loss = 2.542, Train PPL = 12.706, Val Loss = 3.261, Val PPL = 26.076\n",
            "Training Time for additive: 3045.51 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Print loss values to debug overlapping issue\n",
        "for attn_type in results.keys():\n",
        "    print(f\"\\n{attn_type} Attention:\")\n",
        "    print(f\"Train Loss: {results[attn_type]['train_loss']}\")\n",
        "    print(f\"Validation Loss: {results[attn_type]['val_loss']}\")\n",
        "\n",
        "# Generate Performance Plots with markers and different styles\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "colors = {\"general\": \"blue\", \"multiplicative\": \"green\", \"additive\": \"purple\"}\n",
        "markers = {\"general\": \"o\", \"multiplicative\": \"s\", \"additive\": \"d\"}  # Different markers\n",
        "\n",
        "for attn_type in results.keys():\n",
        "    plt.plot(results[attn_type][\"train_loss\"],\n",
        "             label=f\"{attn_type} Train Loss\",\n",
        "             linestyle=\"-\",\n",
        "             linewidth=2,\n",
        "             color=colors[attn_type],\n",
        "             marker=markers[attn_type],\n",
        "             markersize=5)\n",
        "\n",
        "    plt.plot(results[attn_type][\"val_loss\"],\n",
        "             label=f\"{attn_type} Val Loss\",\n",
        "             linestyle=\"--\",\n",
        "             linewidth=2,\n",
        "             color=colors[attn_type],\n",
        "             marker=markers[attn_type],\n",
        "             markersize=5)\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss Comparison\")\n",
        "plt.grid(True)  # Added grid for better readability\n",
        "plt.savefig(\"training_loss_comparison.png\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jggcACsxIO17",
        "outputId": "fbca3e06-5157-4077-aae1-489f3abf2e38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a0d6e9121893>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print loss values to debug overlapping issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mattn_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{attn_type} Attention:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {results[attn_type]['train_loss']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the best attention mechanism\n",
        "best_attn_type = min(results.keys(), key=lambda attn: results[attn][\"val_loss\"][-1])\n",
        "print(f\"Best Attention Mechanism: {best_attn_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5PvxgroEAA8",
        "outputId": "ae1b032e-c0ad-4822-8a78-ffa62a2027af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Attention Mechanism: general\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model\n",
        "best_model = Seq2SeqTransformer(len(vocab_transform[SRC_LANGUAGE]), len(vocab_transform[TRG_LANGUAGE]), attn_type=best_attn_type).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = optim.Adam(best_model.parameters(), lr=0.0005)\n",
        "\n",
        "for epoch in range(10):\n",
        "    best_model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg in train_loader:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = best_model(src, trg[:, :-1])\n",
        "        loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Best Model Train Loss = {epoch_loss / len(train_loader):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLk4inH2GY2g",
        "outputId": "59117e69-1e4c-47a2-fbee-932afe2cee9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Best Model Train Loss = 5.207\n",
            "Epoch 2: Best Model Train Loss = 4.165\n",
            "Epoch 3: Best Model Train Loss = 3.665\n",
            "Epoch 4: Best Model Train Loss = 3.336\n",
            "Epoch 5: Best Model Train Loss = 3.103\n",
            "Epoch 6: Best Model Train Loss = 2.933\n",
            "Epoch 7: Best Model Train Loss = 2.801\n",
            "Epoch 8: Best Model Train Loss = 2.699\n",
            "Epoch 9: Best Model Train Loss = 2.618\n",
            "Epoch 10: Best Model Train Loss = 2.551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in loader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            output, _ = model(src, trg[:, :-1])\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)"
      ],
      "metadata": {
        "id": "PDMjIQE7JHCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "test_loss = evaluate(best_model, test_loader, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxZL35vJINW",
        "outputId": "a993e19c-b741-4569-c3f4-b71d7cf0fb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.258 | Test PPL:  25.985 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best model after training\n",
        "torch.save(best_model.state_dict(), \"best_comic_translator.pth\")\n",
        "print(\"✅ Best model saved as best_comic_translator.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCMUjkgGEBKR",
        "outputId": "7bcdd741-2ae6-42cd-bbd3-d23dc7bda8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Best model saved as best_comic_translator.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9_nTnoylg8s",
        "outputId": "d4503690-18e1-4230-d485-21a2f07e4cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.24.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from PIL import Image\n",
        "\n",
        "# Define the modified code as a string\n",
        "modified_code = \"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_model(model_path):\n",
        "    model = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Save the Streamlit app in Colab's /content directory\n",
        "app_save_path = \"/content/app.py\"\n",
        "\n",
        "# Load the trained model\n",
        "model_path = \"best_comic_translator.pth\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def translate_text(input_text):\n",
        "    tokens = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output = model(tokens)\n",
        "    translated_text = tokenizer.decode(output.argmax(dim=-1)[0], skip_special_tokens=True)\n",
        "    return translated_text\n",
        "\n",
        "# Streamlit UI\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Text Simplifier\", layout=\"centered\")\n",
        "\n",
        "    # Background image\n",
        "    background_image = \"A_creative_blue-themed_background_with_a_smooth_gr.png\"\n",
        "    st.image(background_image, use_column_width=True)\n",
        "\n",
        "    st.title(\"Simplified English Translator\")\n",
        "    st.write(\"Enter an English sentence and get its simplified version!\")\n",
        "\n",
        "    user_input = st.text_area(\"Enter your text:\", \"\")\n",
        "    if st.button(\"Translate\"):\n",
        "        if user_input.strip():\n",
        "            translated_text = translate_text(user_input)\n",
        "            st.success(f\"**Simplified English Translation:** {translated_text}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter a sentence to translate.\")\n",
        "\n",
        "    st.write(\"---\")\n",
        "    st.subheader(\"How It Works\")\n",
        "    st.write(\"This web app uses a Transformer-based model with attention mechanisms to simplify complex English sentences into easier-to-understand versions.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n",
        "\n",
        "# Write the modified code to app.py\n",
        "with open('/content/app.py', 'w') as f:\n",
        "    f.write(modified_code)\n",
        "\n",
        "print(\"Streamlit app has been saved as app.py in /content directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3YYcBJYSscI",
        "outputId": "dad6aa1a-c998-4428-b243-c0bf5999e80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app has been saved as app.py in /content directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "train_losses, val_losses = [], []\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg in train_loader:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, attn_weights = model(src, trg[:, :-1])\n",
        "        loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    train_losses.append(epoch_loss / len(train_loader))\n",
        "    print(f'Epoch {epoch+1}: Train Loss = {epoch_loss / len(train_loader):.3f}')"
      ],
      "metadata": {
        "id": "bD8PdXR6Iz4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941749bf-f5c1-43b4-d894-acb76c6e24e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 5.200\n",
            "Epoch 2: Train Loss = 4.166\n",
            "Epoch 3: Train Loss = 3.665\n",
            "Epoch 4: Train Loss = 3.335\n",
            "Epoch 5: Train Loss = 3.104\n",
            "Epoch 6: Train Loss = 2.934\n",
            "Epoch 7: Train Loss = 2.804\n",
            "Epoch 8: Train Loss = 2.702\n",
            "Epoch 9: Train Loss = 2.620\n",
            "Epoch 10: Train Loss = 2.553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training Loss\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5lYaKtNYLY9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "c0d1d123-ffb4-4a6d-cc2b-ffa93f3a3f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}